{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c2d4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 09:21:21.484123: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-30 09:21:23.182733: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "04/30/2024 09:21:28 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "\n",
      "Downloading config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]\n",
      "Downloading config.json: 100%|##########| 625/625 [00:00<?, ?B/s] \n",
      "\n",
      "Downloading tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]\n",
      "Downloading tokenizer_config.json: 100%|##########| 49.0/49.0 [00:00<00:00, 4.76kB/s]\n",
      "\n",
      "Downloading vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]\n",
      "Downloading vocab.txt: 100%|##########| 996k/996k [00:00<00:00, 1.24MB/s]\n",
      "Downloading vocab.txt: 100%|##########| 996k/996k [00:00<00:00, 1.24MB/s]\n",
      "\n",
      "Downloading tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]\n",
      "Downloading tokenizer.json: 100%|##########| 1.96M/1.96M [00:00<00:00, 2.08MB/s]\n",
      "Downloading tokenizer.json: 100%|##########| 1.96M/1.96M [00:00<00:00, 2.08MB/s]\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "\n",
      "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]\n",
      "Downloading model.safetensors:   1%|1         | 10.5M/714M [00:00<00:26, 26.7MB/s]\n",
      "Downloading model.safetensors:   3%|2         | 21.0M/714M [00:00<00:25, 27.1MB/s]\n",
      "Downloading model.safetensors:   4%|4         | 31.5M/714M [00:01<00:25, 27.0MB/s]\n",
      "Downloading model.safetensors:   6%|5         | 41.9M/714M [00:01<00:25, 26.9MB/s]\n",
      "Downloading model.safetensors:   7%|7         | 52.4M/714M [00:01<00:25, 26.1MB/s]\n",
      "Downloading model.safetensors:   9%|8         | 62.9M/714M [00:02<00:24, 26.5MB/s]\n",
      "Downloading model.safetensors:  10%|#         | 73.4M/714M [00:02<00:24, 26.6MB/s]\n",
      "Downloading model.safetensors:  12%|#1        | 83.9M/714M [00:03<00:23, 26.9MB/s]\n",
      "Downloading model.safetensors:  13%|#3        | 94.4M/714M [00:03<00:23, 26.8MB/s]\n",
      "Downloading model.safetensors:  15%|#4        | 105M/714M [00:03<00:22, 27.0MB/s] \n",
      "Downloading model.safetensors:  16%|#6        | 115M/714M [00:04<00:22, 27.1MB/s]\n",
      "Downloading model.safetensors:  18%|#7        | 126M/714M [00:04<00:21, 27.2MB/s]\n",
      "Downloading model.safetensors:  19%|#9        | 136M/714M [00:05<00:21, 27.3MB/s]\n",
      "Downloading model.safetensors:  21%|##        | 147M/714M [00:05<00:21, 26.9MB/s]\n",
      "Downloading model.safetensors:  22%|##2       | 157M/714M [00:05<00:20, 27.1MB/s]\n",
      "Downloading model.safetensors:  23%|##3       | 168M/714M [00:06<00:20, 26.9MB/s]\n",
      "Downloading model.safetensors:  25%|##4       | 178M/714M [00:06<00:19, 26.9MB/s]\n",
      "Downloading model.safetensors:  26%|##6       | 189M/714M [00:07<00:19, 27.0MB/s]\n",
      "Downloading model.safetensors:  28%|##7       | 199M/714M [00:07<00:18, 27.2MB/s]\n",
      "Downloading model.safetensors:  29%|##9       | 210M/714M [00:07<00:18, 27.0MB/s]\n",
      "Downloading model.safetensors:  31%|###       | 220M/714M [00:08<00:18, 27.2MB/s]\n",
      "Downloading model.safetensors:  32%|###2      | 231M/714M [00:08<00:17, 27.0MB/s]\n",
      "Downloading model.safetensors:  34%|###3      | 241M/714M [00:08<00:17, 27.1MB/s]\n",
      "Downloading model.safetensors:  35%|###5      | 252M/714M [00:09<00:17, 27.2MB/s]\n",
      "Downloading model.safetensors:  37%|###6      | 262M/714M [00:09<00:16, 27.5MB/s]\n",
      "Downloading model.safetensors:  38%|###8      | 273M/714M [00:10<00:15, 27.7MB/s]\n",
      "Downloading model.safetensors:  40%|###9      | 283M/714M [00:10<00:15, 27.4MB/s]\n",
      "Downloading model.safetensors:  41%|####1     | 294M/714M [00:10<00:15, 27.4MB/s]\n",
      "Downloading model.safetensors:  43%|####2     | 304M/714M [00:11<00:15, 27.0MB/s]\n",
      "Downloading model.safetensors:  44%|####4     | 315M/714M [00:11<00:15, 26.3MB/s]\n",
      "Downloading model.safetensors:  46%|####5     | 325M/714M [00:12<00:14, 26.4MB/s]\n",
      "Downloading model.safetensors:  47%|####6     | 336M/714M [00:12<00:14, 26.1MB/s]\n",
      "Downloading model.safetensors:  48%|####8     | 346M/714M [00:12<00:14, 26.1MB/s]\n",
      "Downloading model.safetensors:  50%|####9     | 357M/714M [00:13<00:13, 26.3MB/s]\n",
      "Downloading model.safetensors:  51%|#####1    | 367M/714M [00:13<00:13, 26.2MB/s]\n",
      "Downloading model.safetensors:  53%|#####2    | 377M/714M [00:14<00:13, 25.8MB/s]\n",
      "Downloading model.safetensors:  54%|#####4    | 388M/714M [00:14<00:12, 25.9MB/s]\n",
      "Downloading model.safetensors:  56%|#####5    | 398M/714M [00:14<00:12, 25.9MB/s]\n",
      "Downloading model.safetensors:  57%|#####7    | 409M/714M [00:15<00:11, 26.0MB/s]\n",
      "Downloading model.safetensors:  59%|#####8    | 419M/714M [00:15<00:11, 25.8MB/s]\n",
      "Downloading model.safetensors:  60%|######    | 430M/714M [00:16<00:11, 25.7MB/s]\n",
      "Downloading model.safetensors:  62%|######1   | 440M/714M [00:16<00:10, 25.6MB/s]\n",
      "Downloading model.safetensors:  63%|######3   | 451M/714M [00:16<00:10, 25.8MB/s]\n",
      "Downloading model.safetensors:  65%|######4   | 461M/714M [00:17<00:09, 25.5MB/s]\n",
      "Downloading model.safetensors:  66%|######6   | 472M/714M [00:17<00:09, 25.5MB/s]\n",
      "Downloading model.safetensors:  68%|######7   | 482M/714M [00:18<00:09, 25.6MB/s]\n",
      "Downloading model.safetensors:  69%|######8   | 493M/714M [00:18<00:08, 25.4MB/s]\n",
      "Downloading model.safetensors:  70%|#######   | 503M/714M [00:19<00:09, 22.2MB/s]\n",
      "Downloading model.safetensors:  72%|#######1  | 514M/714M [00:19<00:08, 23.0MB/s]\n",
      "Downloading model.safetensors:  73%|#######3  | 524M/714M [00:20<00:08, 23.6MB/s]\n",
      "Downloading model.safetensors:  75%|#######4  | 535M/714M [00:20<00:07, 23.9MB/s]\n",
      "Downloading model.safetensors:  76%|#######6  | 545M/714M [00:20<00:06, 24.2MB/s]\n",
      "Downloading model.safetensors:  78%|#######7  | 556M/714M [00:21<00:06, 24.2MB/s]\n",
      "Downloading model.safetensors:  79%|#######9  | 566M/714M [00:21<00:05, 24.7MB/s]\n",
      "Downloading model.safetensors:  81%|########  | 577M/714M [00:22<00:05, 24.4MB/s]\n",
      "Downloading model.safetensors:  82%|########2 | 587M/714M [00:22<00:05, 24.3MB/s]\n",
      "Downloading model.safetensors:  84%|########3 | 598M/714M [00:23<00:04, 24.1MB/s]\n",
      "Downloading model.safetensors:  85%|########5 | 608M/714M [00:23<00:04, 24.0MB/s]\n",
      "Downloading model.safetensors:  87%|########6 | 619M/714M [00:23<00:03, 24.2MB/s]\n",
      "Downloading model.safetensors:  88%|########8 | 629M/714M [00:24<00:03, 24.7MB/s]\n",
      "Downloading model.safetensors:  90%|########9 | 640M/714M [00:24<00:03, 23.9MB/s]\n",
      "Downloading model.safetensors:  91%|#########1| 650M/714M [00:25<00:02, 23.9MB/s]\n",
      "Downloading model.safetensors:  92%|#########2| 661M/714M [00:25<00:02, 24.5MB/s]\n",
      "Downloading model.safetensors:  94%|#########3| 671M/714M [00:26<00:01, 24.6MB/s]\n",
      "Downloading model.safetensors:  95%|#########5| 682M/714M [00:26<00:01, 24.9MB/s]\n",
      "Downloading model.safetensors:  97%|#########6| 692M/714M [00:26<00:00, 24.9MB/s]\n",
      "Downloading model.safetensors:  98%|#########8| 703M/714M [00:27<00:00, 25.1MB/s]\n",
      "Downloading model.safetensors: 100%|#########9| 713M/714M [00:27<00:00, 25.2MB/s]\n",
      "Downloading model.safetensors: 100%|##########| 714M/714M [00:27<00:00, 25.7MB/s]\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "04/30/2024 09:22:02 - INFO - __main__ -   Training/evaluation parameters Namespace(model_type='bert', model_name_or_path='bert-base-multilingual-cased', output_dir='output', data_dir='data', train_file='KorQuAD_v1.0_train.json', predict_file='KorQuAD_v1.0_dev.json', config_name='', tokenizer_name='', cache_dir='', version_2_with_negative=False, null_score_diff_threshold=0.0, max_seq_length=512, doc_stride=128, max_query_length=64, do_train=True, do_eval=False, evaluate_during_training=True, do_lower_case=False, per_gpu_train_batch_size=4, per_gpu_eval_batch_size=4, learning_rate=3e-05, gradient_accumulation_steps=1, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, n_best_size=20, max_answer_length=30, verbose_logging=False, lang_id=0, logging_steps=4000, save_steps=4000, eval_all_checkpoints=False, no_cuda=False, overwrite_output_dir=False, overwrite_cache=False, seed=42, local_rank=-1, fp16=False, fp16_opt_level='O1', server_ip='', server_port='', threads=1, n_gpu=0, device=device(type='cpu'))\n",
      "04/30/2024 09:22:02 - INFO - __main__ -   Creating features from dataset file at data\n",
      "\n",
      "  0%|          | 0/1420 [00:00<?, ?it/s]\n",
      "  2%|1         | 22/1420 [00:00<00:06, 217.47it/s]\n",
      "  3%|3         | 44/1420 [00:00<00:11, 123.20it/s]\n",
      "  5%|4         | 65/1420 [00:00<00:09, 150.37it/s]\n",
      "  6%|5         | 83/1420 [00:00<00:08, 155.32it/s]\n",
      "  7%|7         | 101/1420 [00:00<00:09, 137.85it/s]\n",
      "  8%|8         | 118/1420 [00:00<00:09, 139.81it/s]\n",
      " 10%|9         | 139/1420 [00:00<00:08, 153.88it/s]\n",
      " 12%|#1        | 164/1420 [00:01<00:07, 174.52it/s]\n",
      " 13%|#2        | 183/1420 [00:01<00:08, 145.98it/s]\n",
      " 14%|#4        | 202/1420 [00:01<00:08, 148.90it/s]\n",
      " 16%|#5        | 224/1420 [00:01<00:07, 161.89it/s]\n",
      " 17%|#6        | 241/1420 [00:01<00:07, 151.76it/s]\n",
      " 18%|#8        | 258/1420 [00:01<00:07, 148.31it/s]\n",
      " 20%|#9        | 282/1420 [00:01<00:06, 171.09it/s]\n",
      " 21%|##1       | 300/1420 [00:01<00:07, 145.48it/s]\n",
      " 22%|##2       | 316/1420 [00:02<00:07, 148.48it/s]\n",
      " 23%|##3       | 332/1420 [00:02<00:07, 137.50it/s]\n",
      " 25%|##5       | 355/1420 [00:02<00:06, 157.80it/s]\n",
      " 26%|##6       | 375/1420 [00:02<00:06, 166.10it/s]\n",
      " 28%|##8       | 399/1420 [00:02<00:05, 184.90it/s]\n",
      " 30%|##9       | 419/1420 [00:02<00:05, 170.61it/s]\n",
      " 31%|###       | 437/1420 [00:02<00:05, 169.05it/s]\n",
      " 32%|###2      | 455/1420 [00:02<00:05, 164.62it/s]\n",
      " 34%|###3      | 476/1420 [00:03<00:05, 176.19it/s]\n",
      " 35%|###4      | 494/1420 [00:03<00:05, 176.57it/s]\n",
      " 36%|###6      | 517/1420 [00:03<00:04, 190.92it/s]\n",
      " 38%|###8      | 541/1420 [00:03<00:04, 204.22it/s]\n",
      " 40%|###9      | 562/1420 [00:03<00:05, 148.63it/s]\n",
      " 41%|####      | 580/1420 [00:03<00:05, 155.37it/s]\n",
      " 42%|####2     | 598/1420 [00:03<00:05, 140.32it/s]\n",
      " 43%|####3     | 614/1420 [00:03<00:06, 133.39it/s]\n",
      " 44%|####4     | 629/1420 [00:04<00:06, 130.68it/s]\n",
      " 46%|####5     | 647/1420 [00:04<00:05, 142.27it/s]\n",
      " 47%|####6     | 666/1420 [00:04<00:04, 154.06it/s]\n",
      " 48%|####8     | 683/1420 [00:04<00:05, 145.96it/s]\n",
      " 50%|####9     | 703/1420 [00:04<00:04, 159.53it/s]\n",
      " 51%|#####1    | 727/1420 [00:04<00:03, 180.78it/s]\n",
      " 53%|#####2    | 746/1420 [00:04<00:03, 182.64it/s]\n",
      " 54%|#####3    | 766/1420 [00:04<00:03, 186.89it/s]\n",
      " 55%|#####5    | 786/1420 [00:04<00:03, 161.72it/s]\n",
      " 57%|#####6    | 806/1420 [00:05<00:03, 166.73it/s]\n",
      " 58%|#####8    | 824/1420 [00:05<00:03, 160.34it/s]\n",
      " 59%|#####9    | 844/1420 [00:05<00:03, 155.49it/s]\n",
      " 61%|######    | 860/1420 [00:05<00:03, 152.24it/s]\n",
      " 62%|######1   | 876/1420 [00:05<00:03, 146.06it/s]\n",
      " 63%|######2   | 891/1420 [00:06<00:07, 75.56it/s] \n",
      " 64%|######4   | 915/1420 [00:06<00:05, 99.03it/s]\n",
      " 65%|######5   | 929/1420 [00:06<00:04, 106.27it/s]\n",
      " 66%|######6   | 944/1420 [00:06<00:04, 114.98it/s]\n",
      " 68%|######7   | 961/1420 [00:06<00:03, 127.15it/s]\n",
      " 69%|######9   | 982/1420 [00:06<00:03, 143.45it/s]\n",
      " 70%|#######   | 999/1420 [00:06<00:03, 138.98it/s]\n",
      " 72%|#######1  | 1020/1420 [00:06<00:02, 156.30it/s]\n",
      " 73%|#######3  | 1037/1420 [00:06<00:02, 155.26it/s]\n",
      " 74%|#######4  | 1054/1420 [00:07<00:02, 146.79it/s]\n",
      " 76%|#######5  | 1075/1420 [00:07<00:02, 162.71it/s]\n",
      " 77%|#######6  | 1092/1420 [00:07<00:02, 159.69it/s]\n",
      " 78%|#######8  | 1113/1420 [00:07<00:01, 172.76it/s]\n",
      " 80%|#######9  | 1131/1420 [00:07<00:01, 164.88it/s]\n",
      " 81%|########  | 1148/1420 [00:07<00:01, 153.01it/s]\n",
      " 83%|########2 | 1173/1420 [00:07<00:01, 178.04it/s]\n",
      " 84%|########3 | 1192/1420 [00:07<00:01, 180.64it/s]\n",
      " 86%|########5 | 1217/1420 [00:07<00:01, 199.42it/s]\n",
      " 87%|########7 | 1238/1420 [00:08<00:00, 196.07it/s]\n",
      " 89%|########8 | 1258/1420 [00:08<00:00, 181.00it/s]\n",
      " 90%|########9 | 1277/1420 [00:08<00:00, 173.40it/s]\n",
      " 91%|#########1| 1295/1420 [00:08<00:00, 170.03it/s]\n",
      " 92%|#########2| 1313/1420 [00:08<00:00, 167.54it/s]\n",
      " 94%|#########3| 1330/1420 [00:08<00:00, 158.86it/s]\n",
      " 95%|#########4| 1347/1420 [00:08<00:00, 149.10it/s]\n",
      " 96%|#########5| 1363/1420 [00:08<00:00, 151.44it/s]\n",
      " 98%|#########7| 1385/1420 [00:08<00:00, 169.44it/s]\n",
      " 99%|#########8| 1403/1420 [00:09<00:00, 171.75it/s]\n",
      "100%|##########| 1420/1420 [00:09<00:00, 152.63it/s]\n",
      "2024-04-30 09:22:14.429095: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-30 09:22:15.222182: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "convert squad examples to features:   0%|          | 0/60407 [00:00<?, ?it/s]\n",
      "convert squad examples to features:   0%|          | 0/60407 [00:00<?, ?it/s]\n",
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\data\\processors\\squad.py\", line 179, in squad_convert_example_to_features\n",
      "    encoded_dict = tokenizer.encode_plus(  # TODO(thom) update this logic\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 2781, in encode_plus\n",
      "    return self._encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py\", line 517, in _encode_plus\n",
      "    batched_output = self._batch_encode_plus(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py\", line 445, in _batch_encode_plus\n",
      "    encodings = self._tokenizer.encode_batch(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: TextInputSequence must be str\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ITSC\\Desktop\\ChrisProjectGit\\09. NLP\\korquad_model\\run_squad.py\", line 821, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\ITSC\\Desktop\\ChrisProjectGit\\09. NLP\\korquad_model\\run_squad.py\", line 763, in main\n",
      "    train_dataset = load_and_cache_examples(args, tokenizer, evaluate=False, output_examples=False)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ITSC\\Desktop\\ChrisProjectGit\\09. NLP\\korquad_model\\run_squad.py\", line 449, in load_and_cache_examples\n",
      "    features, dataset = squad_convert_examples_to_features(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\data\\processors\\squad.py\", line 376, in squad_convert_examples_to_features\n",
      "    features = list(\n",
      "               ^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tqdm\\std.py\", line 1178, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 423, in <genexpr>\n",
      "    return (item for chunk in result for item in chunk)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 873, in next\n",
      "    raise value\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "      ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\data\\processors\\squad.py\", line 179, in squad_convert_example_to_features\n",
      "    encoded_dict = tokenizer.encode_plus(  # TODO(thom) update this logic\n",
      "  ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 2781, in encode_plus\n",
      "    return self._encode_plus(\n",
      "  ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py\", line 517, in _encode_plus\n",
      "    batched_output = self._batch_encode_plus(\n",
      "  ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py\", line 445, in _batch_encode_plus\n",
      "    encodings = self._tokenizer.encode_batch(\n",
      "  ^^^^^^^^^^^^^^^^^\n",
      "TypeError: TextInputSequence must be str\n"
     ]
    }
   ],
   "source": [
    "!python run_squad.py \\\n",
    "    --model_type bert \\\n",
    "    --model_name_or_path bert-base-multilingual-cased \\\n",
    "    --do_train \\\n",
    "    --train_file KorQuAD_v1.0_train.json \\\n",
    "    --predict_file KorQuAD_v1.0_dev.json \\\n",
    "    --per_gpu_train_batch_size 4 \\\n",
    "    --per_gpu_eval_batch_size 4 \\\n",
    "    --learning_rate 3e-5 \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --max_seq_length 512 \\\n",
    "    --doc_stride 128 \\\n",
    "    --output_dir output \\\n",
    "    --data_dir data \\\n",
    "    --logging_steps 4000 \\\n",
    "    --save_steps 4000 \\\n",
    "    --evaluate_during_training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
